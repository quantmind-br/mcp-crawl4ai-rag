# ===============================
# MCP SERVER CONFIGURATION
# ===============================
TRANSPORT=sse
HOST=0.0.0.0
PORT=8051

# ===============================
# AI MODELS
# ===============================

# Chat Model (for summaries, contextual embeddings)
# Examples: gpt-4o-mini, gpt-3.5-turbo, claude-3-haiku
CHAT_MODEL=gpt-4o-mini
CHAT_API_KEY=
CHAT_API_BASE=

# Embeddings Model (for vector search)
# 
# SUPPORTED PROVIDERS:
# 
# OpenAI (default):
# - text-embedding-3-small (1536 dims, $0.02/1M tokens)
# - text-embedding-3-large (3072 dims, $0.13/1M tokens)
# - text-embedding-ada-002 (1536 dims, $0.10/1M tokens)
#
# DeepInfra (cost-effective alternative):
# - Qwen/Qwen3-Embedding-0.6B (1024 dims, ~$0.01/1M tokens)
# - BAAI/bge-large-en-v1.5 (1024 dims)
# - BAAI/bge-small-en-v1.5 (384 dims)
# - sentence-transformers/all-MiniLM-L6-v2 (384 dims)
#
# RECOMMENDED: Qwen/Qwen3-Embedding-0.6B for best price/performance
EMBEDDINGS_MODEL=Qwen/Qwen3-Embedding-0.6B
EMBEDDINGS_API_KEY=
EMBEDDINGS_API_BASE=https://api.deepinfra.com/v1/openai

# Embedding dimensions (auto-detected from model if not specified)
# 
# AUTO-DETECTION SUPPORTED MODELS:
# - text-embedding-3-small: 1536
# - text-embedding-3-large: 3072
# - Qwen/Qwen3-Embedding-0.6B: 1024
# - BAAI/bge-large-en-v1.5: 1024
# - BAAI/bge-small-en-v1.5: 384
# - sentence-transformers/all-MiniLM-L6-v2: 384
#
# MANUAL OVERRIDE: Set to specific value if needed
# WARNING: Wrong dimensions will trigger automatic collection recreation!
EMBEDDINGS_DIMENSIONS=

# ===============================
# CONFIGURATION EXAMPLES
# ===============================
#
# Example 1: DeepInfra Qwen3 Setup (RECOMMENDED - Cost Effective)
# EMBEDDINGS_MODEL=Qwen/Qwen3-Embedding-0.6B
# EMBEDDINGS_API_KEY=your-deepinfra-api-key
# EMBEDDINGS_API_BASE=https://api.deepinfra.com/v1/openai
# EMBEDDINGS_DIMENSIONS=  # Auto-detected as 1024
#
# Example 2: OpenAI Setup (Higher cost, proven reliability)
# EMBEDDINGS_MODEL=text-embedding-3-small
# EMBEDDINGS_API_KEY=sk-proj-your-openai-key
# EMBEDDINGS_API_BASE=  # Uses OpenAI default
# EMBEDDINGS_DIMENSIONS=  # Auto-detected as 1536
#
# Example 3: Mixed Provider Setup (DeepInfra primary, OpenAI fallback)
# EMBEDDINGS_MODEL=Qwen/Qwen3-Embedding-0.6B
# EMBEDDINGS_API_KEY=your-deepinfra-key
# EMBEDDINGS_API_BASE=https://api.deepinfra.com/v1/openai
# EMBEDDINGS_FALLBACK_MODEL=text-embedding-3-small
# EMBEDDINGS_FALLBACK_API_KEY=sk-proj-your-openai-key
# EMBEDDINGS_FALLBACK_API_BASE=https://api.openai.com/v1
#
# Example 4: Custom Dimensions Override
# EMBEDDINGS_MODEL=Qwen/Qwen3-Embedding-0.6B
# EMBEDDINGS_API_KEY=your-deepinfra-key
# EMBEDDINGS_API_BASE=https://api.deepinfra.com/v1/openai
# EMBEDDINGS_DIMENSIONS=1024  # Explicit override (normally auto-detected)

# Fallback Models
CHAT_FALLBACK_MODEL=gpt-4o-mini
EMBEDDINGS_FALLBACK_MODEL=text-embedding-3-small

# Fallback API Configuration (optional - inherits from primary if not set)
# 
# PURPOSE: Enable true API provider failover for resilience and flexibility
# 
# INHERITANCE BEHAVIOR:
# - If CHAT_FALLBACK_API_KEY is not set, inherits CHAT_API_KEY
# - If CHAT_FALLBACK_API_BASE is not set, inherits CHAT_API_BASE
# - Same inheritance pattern applies to EMBEDDINGS_FALLBACK_* variables
#
# USE CASES:
# 1. Resilience: Primary API down, automatic failover to different provider
# 2. Cost optimization: Premium primary provider, cheaper fallback provider
# 3. Rate limiting: Fallback to unrestricted provider when primary is rate limited
# 4. Regional compliance: Different providers for different geographical requirements
#
# CONFIGURATION EXAMPLES:
#
# Example 1: Mixed providers (Primary: OpenRouter, Fallback: OpenAI)
# CHAT_API_KEY=sk-or-v1-your-openrouter-key
# CHAT_API_BASE=https://openrouter.ai/api/v1
# CHAT_FALLBACK_API_KEY=sk-proj-your-openai-key
# CHAT_FALLBACK_API_BASE=https://api.openai.com/v1
#
# Example 2: Inheritance (Fallback uses same provider with inherited config)
# CHAT_API_KEY=your-primary-key
# CHAT_API_BASE=https://api.yourprovider.com/v1
# CHAT_FALLBACK_MODEL=gpt-3.5-turbo  # Only model differs, API config inherited
#
# Example 3: Azure primary, OpenAI fallback
# CHAT_API_KEY=your-azure-key
# CHAT_API_BASE=https://your-resource.openai.azure.com/
# CHAT_FALLBACK_API_KEY=sk-proj-your-openai-key
# CHAT_FALLBACK_API_BASE=https://api.openai.com/v1
#
# TROUBLESHOOTING:
# - If both primary and fallback fail: Check API keys and network connectivity
# - Inheritance not working: Verify primary configuration is set correctly
# - Wrong provider used: Check that fallback base URL is explicitly set for different providers
#
# Optional: Set only if you want different API configuration for fallback
CHAT_FALLBACK_API_KEY=
CHAT_FALLBACK_API_BASE=
EMBEDDINGS_FALLBACK_API_KEY=
EMBEDDINGS_FALLBACK_API_BASE=

# ===============================
# RAG FEATURES
# ===============================
USE_CONTEXTUAL_EMBEDDINGS=false
USE_HYBRID_SEARCH=false
USE_AGENTIC_RAG=false
USE_RERANKING=false
USE_KNOWLEDGE_GRAPH=false

# ===============================
# GPU ACCELERATION
# ===============================
# Options: auto|cuda|mps|cpu
USE_GPU_ACCELERATION=auto
# Options: float32|float16|bfloat16
GPU_PRECISION=float32
GPU_DEVICE_INDEX=0
GPU_MEMORY_FRACTION=0.8

# ===============================
# DATABASES
# ===============================

# Qdrant Vector Database
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Neo4j Knowledge Graph
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password123

# ===============================
# HTTP CLIENT CONFIGURATION
# ===============================
# ConnectionResetError fix settings for Windows stability
# These are automatically applied but can be overridden here

# Enable HTTP/2 for better performance (true/false)
HTTPX_HTTP2=true

# Maximum total HTTP connections for crawling operations
# Higher values = faster crawling, more resource usage
# Default: 200 (optimized for performance)
HTTPCORE_MAX_CONNECTIONS=200

# Maximum keepalive connections to reuse
# Higher values = better connection reuse, less overhead
# Default: 50 (balanced performance)
HTTPCORE_MAX_KEEPALIVE_CONNECTIONS=50

# Connection keepalive expiry time in seconds
# Longer values = better connection reuse, more memory usage
# Default: 30.0 (optimized for stability)
HTTPCORE_KEEPALIVE_EXPIRY=30.0