# Tree-sitter Multi-Language Code Analysis Integration

## Goal

**Feature Goal**: Refactor existing Python AST-based code analysis tools to use Tree-sitter for multi-language support (Python, TypeScript, Java), enabling hallucination detection and knowledge graph population for any supported language.

**Deliverable**: Enhanced `parse_github_repository` and `check_ai_script_hallucinations` MCP tools that can analyze repositories and validate AI-generated scripts in multiple programming languages, with all results stored in the existing Neo4j knowledge graph schema.

**Success Definition**: 
- Successfully parse TypeScript/Java repositories and populate Neo4j with classes, methods, functions, and imports
- Validate AI-generated TypeScript/Java scripts against the knowledge graph for hallucination detection
- Maintain 100% backward compatibility with existing Python analysis functionality
- Pass all existing tests and new multi-language integration tests

## User Persona

**Target User**: AI coding assistants and developers using the MCP Crawl4AI RAG server

**Use Case**: AI agents need to validate generated code across multiple programming languages by checking if referenced classes, methods, and imports actually exist in analyzed repositories

**User Journey**:
1. User runs `parse_github_repository` on a mixed-language repository (Python + TypeScript)
2. System analyzes both Python and TypeScript files, extracting code structure using Tree-sitter
3. Neo4j knowledge graph is populated with entities from both languages
4. User runs `check_ai_script_hallucinations` on a TypeScript script generated by an AI
5. System validates the script against the knowledge graph and detects any hallucinations (non-existent methods, classes, etc.)

**Pain Points Addressed**: 
- Current system only works with Python files, limiting usefulness for polyglot codebases
- AI hallucination detection is restricted to Python, while many modern projects use TypeScript, Java, etc.
- Manual analysis of multi-language repositories is time-consuming and error-prone

## Why

- **Expand Coverage**: Most modern repositories contain multiple languages - enabling analysis of TypeScript/Java significantly increases the system's utility
- **AI Safety**: AI coding assistants frequently hallucinate non-existent APIs in any language - multi-language validation prevents broken generated code  
- **Zero Disruption**: Tree-sitter integration maintains the existing API and data structures while adding language support
- **Performance**: Tree-sitter's error-recovery parsing handles real-world code better than language-specific AST parsers

## What

Replace Python `ast` module usage in knowledge graph analysis tools with Tree-sitter-based parsing that supports multiple languages while maintaining identical output structure and API compatibility.

### Success Criteria

- [ ] `parse_github_repository` successfully analyzes repositories containing Python, TypeScript, and Java files
- [ ] `check_ai_script_hallucinations` validates AI-generated scripts in TypeScript and Java  
- [ ] Neo4j knowledge graph contains classes, methods, functions from all supported languages
- [ ] All existing Python-based functionality continues to work without changes
- [ ] New multi-language integration tests pass with 100% success rate
- [ ] Performance comparable to or better than current AST-based implementation

## All Needed Context

### Context Completeness Check

_This PRP provides complete implementation guidance for someone unfamiliar with both Tree-sitter and the existing codebase, including specific file patterns, query examples, error handling strategies, and integration points._

### Documentation & References

```yaml
# MUST READ - Critical for implementation success
- docfile: PRPs/ai_docs/treesitter_multi_language_integration.md
  why: Complete Tree-sitter integration patterns, query examples, error handling
  critical: Contains the exact parser factory pattern and data structure mapping needed

- url: https://tree-sitter.github.io/tree-sitter/using-parsers#pattern-matching-with-queries
  why: Core query syntax and S-expression patterns for extracting code structures
  critical: Query patterns are language-specific and must be precisely formatted

- url: https://github.com/tree-sitter/py-tree-sitter#usage
  why: Python binding usage patterns, parser setup, performance optimization
  critical: Shows exact API usage and memory management patterns

- file: knowledge_graphs/parse_repo_into_neo4j.py
  why: Current AST-based parsing logic that needs Tree-sitter replacement
  pattern: Lines 181-335 show exact data structure expected by Neo4j schema
  gotcha: Must preserve exact dictionary structure for backward compatibility

- file: knowledge_graphs/ai_script_analyzer.py  
  why: Current Python-only script analysis that needs multi-language support
  pattern: Lines 92-141 show analysis workflow that must be preserved
  gotcha: AnalysisResult dataclass structure (lines 77-89) is used by downstream validation

- file: src/features/github_processor.py
  why: File discovery logic that already supports multiple extensions
  pattern: Lines 590-744 MultiFileDiscovery class shows extension handling
  gotcha: File size limits and exclusion patterns must be preserved

- url: https://github.com/tree-sitter/tree-sitter-python/blob/master/queries/highlights.scm
  why: Example query patterns for Python language constructs  
  critical: Shows exact node names and structure for Python AST equivalents

- url: https://github.com/tree-sitter/tree-sitter-typescript/blob/master/queries/highlights.scm
  why: TypeScript-specific node names for classes, interfaces, functions
  critical: TypeScript has different AST structure than Python (interfaces vs classes)

- url: https://github.com/tree-sitter/tree-sitter-java/blob/master/queries/highlights.scm
  why: Java-specific patterns for packages, classes, methods
  critical: Java has unique constructs like packages that need special handling
```

### Current Codebase Structure

```bash
# Existing files that need modification
knowledge_graphs/
├── parse_repo_into_neo4j.py          # Replace AST logic with Tree-sitter
├── ai_script_analyzer.py             # Add multi-language analysis
├── ai_hallucination_detector.py      # Update for multi-language support
src/features/
├── github_processor.py               # Already supports multi-file discovery
pyproject.toml                        # Add tree-sitter dependency
```

### Desired Codebase Structure with New Files

```bash
# New Tree-sitter integration layer
knowledge_graphs/
├── language_parser.py                # Abstract base class for parsers
├── tree_sitter_parser.py             # Main Tree-sitter implementation  
├── parser_factory.py                 # Parser selection and caching
├── query_patterns/
│   ├── python_queries.py             # Python-specific S-expression queries
│   ├── typescript_queries.py         # TypeScript/interface queries
│   └── java_queries.py               # Java package/class queries
├── build_grammars.py                 # Grammar compilation script
├── grammars/                         # Cloned Tree-sitter grammars (git ignored)
│   ├── tree-sitter-python/
│   ├── tree-sitter-typescript/
│   └── tree-sitter-java/
build/
└── languages.so                      # Compiled grammar library

# New test coverage
tests/
├── test_tree_sitter_parser.py        # Unit tests for Tree-sitter parsing
├── test_multi_language_integration.py # Integration tests across languages
└── fixtures/
    ├── sample_python.py              # Test data for each language
    ├── sample_typescript.ts
    └── sample_java.java
```

### Known Gotchas & Library Quirks

```python
# CRITICAL: Tree-sitter requires C++ compiler for grammar compilation
# Windows: Needs Visual Studio Build Tools or full Visual Studio
# Linux/macOS: Needs GCC/Clang installed
# This is a build-time requirement, not runtime

# CRITICAL: Query syntax is extremely sensitive to whitespace and parentheses
# WRONG: (function_definition name:(identifier) @name)
# RIGHT: (function_definition name: (identifier) @name)

# CRITICAL: Language grammar loading must happen after build_grammars.py runs
# The languages.so file must exist before importing Language objects
if not os.path.exists('build/languages.so'):
    raise RuntimeError("Run 'python knowledge_graphs/build_grammars.py' first")

# CRITICAL: Tree-sitter parsing returns bytes, not strings
tree = parser.parse(content.encode('utf-8'))  # Must encode to bytes
node_text = content[node.start_byte:node.end_byte]  # Slicing returns bytes

# CRITICAL: Existing Neo4j schema expects specific field names and types
# Data structure from Tree-sitter MUST match AST parser output exactly:
expected_structure = {
    'classes': [{'name': str, 'full_name': str, 'methods': [...], 'attributes': [...]}],
    'functions': [{'name': str, 'full_name': str, 'params': [...], 'return_type': str}],
    'imports': [str, str, ...]  # List of import names
}

# CRITICAL: Multi-language file extensions need explicit mapping  
# github_processor.py already has this logic but may need extension
SUPPORTED_EXTENSIONS = {'.py', '.ts', '.tsx', '.js', '.jsx', '.java'}

# CRITICAL: TypeScript has two variants (TypeScript and TSX) requiring different parsers
# Both use same queries but different Language objects
```

## Implementation Blueprint

### Data Models and Structure

The existing data structures in the codebase already provide the foundation. No new models needed - Tree-sitter output must match the existing AST output format exactly.

```python
# PRESERVE: Existing AnalysisResult structure in ai_script_analyzer.py (lines 77-89)
@dataclass
class AnalysisResult:
    file_path: str
    imports: List[ImportInfo] = field(default_factory=list)
    class_instantiations: List[ClassInstantiation] = field(default_factory=list)
    method_calls: List[MethodCall] = field(default_factory=list)
    # ... rest of existing structure

# PRESERVE: Neo4j data structure from parse_repo_into_neo4j.py (lines 324-331)
return {
    'module_name': module_name,
    'file_path': relative_path, 
    'classes': classes,      # List[Dict] with name, full_name, methods, attributes
    'functions': functions,  # List[Dict] with name, full_name, params, return_type
    'imports': imports,      # List[str] 
    'line_count': line_count
}
```

### Implementation Tasks (ordered by dependencies)

```yaml
Task 1: CREATE pyproject.toml dependency update
  - ADD: "tree-sitter>=0.21.0" to dependencies list (after line 24)
  - FOLLOW pattern: Existing dependency format in pyproject.toml
  - NAMING: Use exact version constraint format as other deps
  - PLACEMENT: Add after existing parsing/analysis dependencies
  - CRITICAL: Do not modify existing torch URLs - add tree-sitter only

Task 2: CREATE knowledge_graphs/build_grammars.py
  - IMPLEMENT: Grammar cloning and compilation script
  - FOLLOW pattern: PRPs/ai_docs/treesitter_multi_language_integration.md build script section
  - NAMING: build_grammars() function, grammars/ subdirectory
  - DEPENDENCIES: None - this is foundation for other tasks
  - PLACEMENT: Root level in knowledge_graphs/
  - CRITICAL: Must create build/languages.so file that other components expect

Task 3: CREATE knowledge_graphs/language_parser.py  
  - IMPLEMENT: LanguageParser abstract base class with parse() method
  - FOLLOW pattern: ABC pattern from PRPs/ai_docs/treesitter_multi_language_integration.md
  - NAMING: LanguageParser class, parse(file_content: str, file_path: str) -> Dict[str, Any]
  - DEPENDENCIES: Task 1 (tree-sitter dependency)
  - PLACEMENT: Abstract base class in knowledge_graphs/
  - CRITICAL: Return type must match existing AST parser output structure

Task 4: CREATE knowledge_graphs/query_patterns/ directory and query files
  - IMPLEMENT: python_queries.py, typescript_queries.py, java_queries.py
  - FOLLOW pattern: Query examples in PRPs/ai_docs/treesitter_multi_language_integration.md
  - NAMING: LANGUAGE_QUERIES dictionary with 'classes', 'functions', 'methods', 'imports' keys
  - DEPENDENCIES: Task 1 (tree-sitter), research from external grammar repos
  - PLACEMENT: Separate module for each language's query patterns
  - CRITICAL: S-expression syntax must be exactly correct or queries fail silently

Task 5: CREATE knowledge_graphs/parser_factory.py
  - IMPLEMENT: ParserFactory class with get_parser() and detect_language() methods  
  - FOLLOW pattern: Factory pattern from PRPs/ai_docs/treesitter_multi_language_integration.md
  - NAMING: ParserFactory class, extension mapping, parser caching
  - DEPENDENCIES: Task 2 (grammar build), Task 3 (base class), Task 4 (queries)
  - PLACEMENT: Central factory in knowledge_graphs/
  - CRITICAL: Must handle 'unknown' language gracefully and cache parsers for performance

Task 6: CREATE knowledge_graphs/tree_sitter_parser.py
  - IMPLEMENT: TreeSitterParser class implementing LanguageParser interface
  - FOLLOW pattern: Parser implementation from PRPs/ai_docs/treesitter_multi_language_integration.md  
  - NAMING: TreeSitterParser class, language-specific parse methods
  - DEPENDENCIES: Task 3 (interface), Task 4 (queries), Task 5 (factory)
  - PLACEMENT: Main implementation class in knowledge_graphs/
  - CRITICAL: Output structure must exactly match existing AST parser format

Task 7: MODIFY knowledge_graphs/parse_repo_into_neo4j.py
  - REPLACE: analyze_python_file() method with analyze_file() using Tree-sitter
  - FOLLOW pattern: Existing method signature and return structure (lines 181-335)
  - PRESERVE: All existing Neo4j schema, data structures, error handling
  - DEPENDENCIES: Task 6 (parser implementation)
  - CRITICAL: get_python_files() method needs to become get_supported_files() for multiple extensions

Task 8: MODIFY knowledge_graphs/ai_script_analyzer.py  
  - REPLACE: AST parsing in analyze_script() with Tree-sitter multi-language support
  - FOLLOW pattern: Existing AnalysisResult structure and method signatures (lines 102-141)
  - PRESERVE: All existing dataclass structures and analysis workflow
  - DEPENDENCIES: Task 6 (parser implementation)
  - CRITICAL: Must handle non-Python files while maintaining Python compatibility

Task 9: MODIFY src/features/github_processor.py
  - EXTEND: SUPPORTED_EXTENSIONS set to include .ts, .tsx, .java (around line 593)
  - FOLLOW pattern: Existing MultiFileDiscovery class extension handling
  - PRESERVE: All existing file size limits and exclusion patterns  
  - DEPENDENCIES: Task 6 (parser for new file types)
  - CRITICAL: Do not break existing markdown/config file processing

Task 10: CREATE tests/test_tree_sitter_parser.py
  - IMPLEMENT: Unit tests for Tree-sitter parsing of each supported language
  - FOLLOW pattern: Existing test structure in tests/test_github_processor.py
  - NAMING: test_python_parsing, test_typescript_parsing, test_java_parsing methods
  - DEPENDENCIES: Task 6 (parser implementation)
  - PLACEMENT: Unit tests in tests/
  - CRITICAL: Test exact output structure compatibility with existing AST tests

Task 11: CREATE tests/test_multi_language_integration.py
  - IMPLEMENT: Integration tests for full multi-language workflow
  - FOLLOW pattern: End-to-end test approach from existing tests
  - NAMING: test_mixed_language_repository, test_typescript_hallucination_detection
  - DEPENDENCIES: Task 7, Task 8 (modified core components)
  - PLACEMENT: Integration tests in tests/
  - CRITICAL: Must test actual Neo4j population and hallucination detection across languages

Task 12: CREATE tests/fixtures/ directory with sample code
  - IMPLEMENT: sample_python.py, sample_typescript.ts, sample_java.java test files
  - FOLLOW pattern: Representative code samples with classes, methods, imports
  - NAMING: Descriptive test data that covers all language constructs
  - DEPENDENCIES: Task 10, Task 11 (test files that need fixtures)
  - PLACEMENT: Test data in tests/fixtures/
  - CRITICAL: Sample code must include edge cases and error conditions for robust testing
```

### Implementation Patterns & Key Details

```python
# Tree-sitter parser replacement pattern for existing AST logic
# OLD (in parse_repo_into_neo4j.py line ~189):
tree = ast.parse(content)
for node in ast.walk(tree):
    if isinstance(node, ast.ClassDef):
        # ... extract class info

# NEW (Tree-sitter replacement):
parser = self.parser_factory.get_parser(language)
if not parser:
    return None  # Graceful fallback for unsupported languages
    
tree_sitter_tree = parser.parse(content.encode('utf-8'))
result = self.tree_sitter_parser.parse(content, file_path, language)
# result has identical structure to AST output

# CRITICAL: Query pattern example (exact S-expression syntax required)
PYTHON_QUERIES = {
    'classes': '''
        (class_definition 
            name: (identifier) @class_name
            body: (block) @class_body) @class_def
    ''',
    'functions': '''
        (function_definition 
            name: (identifier) @func_name
            parameters: (parameters) @params) @func_def
    '''
}

# CRITICAL: Error handling pattern for parse failures
def safe_parse_with_fallback(self, content: str, file_path: str):
    try:
        # Primary: Tree-sitter parsing
        result = self.tree_sitter_parser.parse(content, file_path, language)
        if result and (result['classes'] or result['functions']):
            return result
    except Exception as e:
        logger.warning(f"Tree-sitter parsing failed: {e}")
    
    # Fallback: AST parsing for Python only
    if language == 'python':
        return self._fallback_ast_parse(content, file_path)
    
    # Final fallback: Empty structure maintains API compatibility
    return {'classes': [], 'functions': [], 'imports': []}

# CRITICAL: Language detection with multi-layer strategy  
def detect_language(self, file_path: str) -> str:
    # 1. File extension (primary)
    extension_map = {'.py': 'python', '.ts': 'typescript', '.tsx': 'typescript', '.java': 'java'}
    ext = Path(file_path).suffix.lower()
    return extension_map.get(ext, 'unknown')
```

### Integration Points

```yaml
NEO4J_SCHEMA:
  - preserve: Existing node types (Repository, File, Class, Method, Function, Attribute)
  - preserve: All relationship types (CONTAINS, DEFINES, HAS_METHOD, HAS_ATTRIBUTE)
  - extend: Add 'language' property to File nodes for multi-language identification

MCP_TOOLS:
  - preserve: parse_github_repository tool signature and response format
  - preserve: check_ai_script_hallucinations tool signature and response format  
  - extend: Both tools now accept files in multiple languages transparently

CONFIG:
  - add to: pyproject.toml dependencies section
  - pattern: "tree-sitter>=0.21.0" following existing dependency format

COMMAND_LINE:
  - add: python knowledge_graphs/build_grammars.py (run once during setup)
  - preserve: All existing command patterns for parse_repo_into_neo4j.py
```

## Validation Loop

### Level 1: Syntax & Style (Immediate Feedback)

```bash
# Run after each new file creation
uv run ruff check knowledge_graphs/tree_sitter_parser.py --fix
uv run mypy knowledge_graphs/tree_sitter_parser.py  
uv run ruff format knowledge_graphs/tree_sitter_parser.py

# Run after grammar build script
python knowledge_graphs/build_grammars.py
ls -la build/languages.so  # Verify shared library created

# Full project validation
uv run ruff check . --fix
uv run mypy src/ knowledge_graphs/
uv run ruff format .

# Expected: Zero errors, build/languages.so exists and is >1MB
```

### Level 2: Unit Tests (Component Validation)

```bash
# Test Tree-sitter parser component isolation
uv run pytest tests/test_tree_sitter_parser.py::test_python_parsing -v
uv run pytest tests/test_tree_sitter_parser.py::test_typescript_parsing -v  
uv run pytest tests/test_tree_sitter_parser.py::test_java_parsing -v

# Test data structure compatibility  
uv run pytest tests/test_tree_sitter_parser.py::test_output_structure_matches_ast -v

# Test error handling and fallbacks
uv run pytest tests/test_tree_sitter_parser.py::test_invalid_syntax_handling -v

# Expected: All parsing tests pass, output structures match AST format exactly
```

### Level 3: Integration Testing (System Validation)

```bash
# Test multi-language repository analysis
uv run python knowledge_graphs/parse_repo_into_neo4j.py \
  "https://github.com/microsoft/TypeScript-Node-Starter.git"

# Verify Neo4j population with TypeScript entities
uv run python -c "
from knowledge_graphs.query_knowledge_graph import query_neo4j_direct
result = query_neo4j_direct('MATCH (c:Class) WHERE c.full_name CONTAINS \"typescript\" RETURN count(c)')
print(f'TypeScript classes in Neo4j: {result}')
"

# Test TypeScript hallucination detection
echo 'const user = new NonExistentClass(); user.fakeMethod();' > test_hallucination.ts
uv run python knowledge_graphs/ai_hallucination_detector.py test_hallucination.ts

# Test backwards compatibility with Python
uv run pytest tests/test_github_processor.py -v  # Should still pass

# Expected: TypeScript entities in Neo4j, hallucinations detected, Python tests pass
```

### Level 4: Creative & Domain-Specific Validation

```bash
# Real-world multi-language repository test
uv run python knowledge_graphs/parse_repo_into_neo4j.py \
  "https://github.com/vercel/next.js.git"  # Large TypeScript/JavaScript project

# Performance benchmark (should be comparable to AST)
time python knowledge_graphs/parse_repo_into_neo4j.py \
  "https://github.com/pallets/flask.git"    # Pure Python project

# Multi-language hallucination detection test
cat > mixed_language_test.py << 'EOF'
# Python file trying to import TypeScript concepts
from some_typescript_module import ReactComponent  # Should detect as hallucination
class MyClass(ReactComponent):  # Should validate against actual TS classes
    def render(self):
        return self.props.children  # Should validate TS interface methods
EOF

uv run python knowledge_graphs/ai_hallucination_detector.py mixed_language_test.py

# Complex parsing edge cases
uv run pytest tests/test_multi_language_integration.py::test_parsing_errors -v
uv run pytest tests/test_multi_language_integration.py::test_incomplete_syntax -v

# Expected: Large repos parsed successfully, performance within 2x of AST, edge cases handled
```

## Final Validation Checklist

### Technical Validation

- [ ] All 4 validation levels completed successfully
- [ ] Grammar build produces valid build/languages.so file
- [ ] All tests pass: `uv run pytest tests/ -v`
- [ ] No linting errors: `uv run ruff check .`
- [ ] No type errors: `uv run mypy src/ knowledge_graphs/`
- [ ] No formatting issues: `uv run ruff format . --check`

### Feature Validation

- [ ] TypeScript repository analysis populates Neo4j with classes, interfaces, methods
- [ ] Java repository analysis extracts packages, classes, methods correctly
- [ ] TypeScript AI script hallucination detection works correctly
- [ ] Java AI script hallucination detection identifies non-existent APIs  
- [ ] Python analysis continues to work exactly as before (backwards compatibility)
- [ ] Multi-language repositories (Python + TypeScript) analyze all files correctly

### Code Quality Validation

- [ ] Tree-sitter parser follows existing error handling patterns from AST parser
- [ ] File placement matches desired codebase structure
- [ ] Data structures exactly match existing Neo4j schema expectations
- [ ] Parser factory properly caches instances and handles unknown languages
- [ ] Query patterns follow Tree-sitter best practices and handle edge cases
- [ ] Integration preserves all existing MCP tool signatures and response formats

### Documentation & Deployment

- [ ] Grammar build process documented and automated
- [ ] Multi-language support transparent to existing API consumers
- [ ] Error messages informative when Tree-sitter dependencies missing
- [ ] Performance characteristics documented and acceptable

---

## Anti-Patterns to Avoid

- ❌ Don't change existing Neo4j schema or data structures - maintain exact compatibility
- ❌ Don't skip grammar building - other components depend on languages.so file
- ❌ Don't ignore Tree-sitter parsing errors - implement proper fallback strategies  
- ❌ Don't hardcode query patterns - use separate modules for maintainability
- ❌ Don't break existing Python functionality - preserve AST parsing as fallback
- ❌ Don't skip performance testing - Tree-sitter should be comparable to AST parsing
- ❌ Don't modify MCP tool APIs - changes must be transparent to consumers